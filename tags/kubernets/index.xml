<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kubernets on CC&#39;s Trip</title>
    <link>https://cctrip.github.io/tags/kubernets/</link>
    <description>Recent content in kubernets on CC&#39;s Trip</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 16 Aug 2021 17:55:28 +0800</lastBuildDate><atom:link href="https://cctrip.github.io/tags/kubernets/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Traefik系列(一)：Ingress Controller</title>
      <link>https://cctrip.github.io/posts/why_traefik/</link>
      <pubDate>Mon, 16 Aug 2021 17:55:28 +0800</pubDate>
      
      <guid>https://cctrip.github.io/posts/why_traefik/</guid>
      <description>1. 介绍    最近，我们在拥抱云原生，准备基于k8s开发一套PaaS平台，我这边负责了服务路由相关的功能，因此，要选出一个Ingress Controller来实现我们的服务路由相关的功能，市面上那么多种，哪个才是最适合我们的呢？
 2. 需求    在EC2时代，我们用openresty来实现我们的服务路由功能，线上有几十上百个域名，基于稳定性和安全的考虑，通过人工配置和git来管理server和location模块，开发测试环境，不同的项目环境，基线环境等等，服务路由配置更是成倍数的增长，因此我们通过openresty+lua，以及DevOps平台来动态管理服务路由的变更。
同时，基于安全和稳定性的考虑，我们在线上环境基于lua写了一些简单的waf，来防攻击以及限流操作。
在容器上，我们的标准将不同的应用划分为不同的namespace，但是域名又是统一的。
基于以上的各类需求，因此，在k8s上的服务路由功能至少要具备以下功能，
 多域名转发 跨namespace配置location tls支持 tcp和udp转发 限流 api支持 动态加载配置文件 metric监控 跨域支持 重写支持 外部域名转发   3. 对比    ​	选型
data plane &amp;ndash; control plane
envoy &amp;ndash;&amp;gt; gloo|Ambassador | istio
nginx &amp;ndash;&amp;gt; kong|apisix
traefik &amp;ndash;&amp;gt; traefik
   control plane data plane backend service discovery protocols ssl termination websocket routing scope resiliency lb algorithms auth Tracing canary/shadow istio integration state Paid support Linkaaaaaaaaaaaaaa dashboard sticky sessions lua     ingress-nginx nginx dynamic http,https,tcp (separate lb),udp,grpc,fastcgi,IPC socket yes yes host,path(with regex) cross-namespace rate limit, retries rr,ewma,ip_hash basic, digest, external auth yes canary  kubernetes  https://kubernetes.</description>
    </item>
    
    <item>
      <title>深入理解LVS</title>
      <link>https://cctrip.github.io/posts/deep_lvs/</link>
      <pubDate>Mon, 09 Nov 2020 17:55:28 +0800</pubDate>
      
      <guid>https://cctrip.github.io/posts/deep_lvs/</guid>
      <description>1. 介绍    接上一篇深入理解iptables，kubernetes service技术还用到ipvs技术，讲到ipvs，那就得说说LVS了，这篇我们来了解下LVS具体的实现机制。
 2. IPVS     IPVS（IP虚拟服务器）实现传输层负载均衡，通常称为第4层LAN交换。
 负载均衡器的概念可以看这篇文章，或者翻译版本。
大多数情况下，负载均衡器和代理这两个术语会被混用在一起，所谓的代理，简单来说，就是接收客户端的数据包再转发到对应的后端服务器上。
ipvs就在这样的软件，它依赖netfilter的功能来实现数据包的转发，我们还是先拉源码定义来看下。
ip_vs_core.c
static const struct nf_hook_ops ip_vs_ops4[] = { /* After packet filtering, change source only for VS/NAT */ { .hook	= ip_vs_reply4, .pf	= NFPROTO_IPV4, .hooknum	= NF_INET_LOCAL_IN, .priority	= NF_IP_PRI_NAT_SRC - 2, }, /* After packet filtering, forward packet through VS/DR, VS/TUN, * or VS/NAT(change destination), so that filtering rules can be * applied to IPVS.</description>
    </item>
    
    <item>
      <title>深入理解iptables</title>
      <link>https://cctrip.github.io/posts/deep_iptables/</link>
      <pubDate>Sat, 07 Nov 2020 17:55:28 +0800</pubDate>
      
      <guid>https://cctrip.github.io/posts/deep_iptables/</guid>
      <description>1. 介绍    最近在刚好在看Kubernetes的service相关内容，里面用到了iptables和ipvs技术，好久没看iptables了，快忘记了，刚好复习重新记忆一下。
讲iptables和ipvs，有个东西就一定得清楚，那就是netfilter
 2. netfilter     netfilter是一个数据包处理框架。
 netfilter具备以下几个功能：
 数据包过滤 网络地址(端口)转换 数据包日志记录 用户空间数据包排队 其他数据包处理功能  2.1 netfilter架构    netfilter 提供了 5 个 hook 点。包经过协议栈时会触发内核模块注册在这里的处理函数 。触发哪个 hook 取决于包的方向（是发送还是接收）、包的目的地址、以及包在上一个 hook 点是被丢弃还是拒绝等等。
下面几个 hook 是内核协议栈中已经定义好的：
 NF_IP_PRE_ROUTING: 接收到的包进入协议栈后立即触发此 hook，在进行任何路由判断 （将包发往哪里）之前 NF_IP_LOCAL_IN: 接收到的包经过路由判断，如果目的是本机，将触发此 hook NF_IP_FORWARD: 接收到的包经过路由判断，如果目的是其他机器，将触发此 hook NF_IP_LOCAL_OUT: 本机产生的准备发送的包，在进入协议栈后立即触发此 hook NF_IP_POST_ROUTING: 本机产生的准备发送的包或者转发的包，在经过路由判断之后， 将触发此 hook  注册处理函数时必须提供优先级，以便 hook 触发时能按照 优先级高低调用处理函数。这使得多个模块（或者同一内核模块的多个实例）可以在同一 hook 点注册，并且有确定的处理顺序。内核模块会依次被调用，每次返回一个结果给 netfilter 框架，提示该对这个包做以下几个操作之一：</description>
    </item>
    
  </channel>
</rss>
