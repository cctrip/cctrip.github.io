<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Golang on CC&#39;s Trip</title>
    <link>https://cctrip.tech/categories/golang/</link>
    <description>Recent content in Golang on CC&#39;s Trip</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 07 Apr 2020 17:55:28 +0800</lastBuildDate><atom:link href="https://cctrip.tech/categories/golang/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Go系列：并发</title>
      <link>https://cctrip.tech/posts/go_series_conc/</link>
      <pubDate>Tue, 07 Apr 2020 17:55:28 +0800</pubDate>
      
      <guid>https://cctrip.tech/posts/go_series_conc/</guid>
      <description>系列目录    《Go系列：内存管理》
《Go系列：调度器》
《Go系列：并发》
 1. 介绍    2. 面向并发的内存模型     Go内存模型指定了一种条件，在这种条件下，可以保证在一个goroutine中读取变量可以观察到在不同goroutine中写入同一变量所产生的值。
 程序如果修改被多个协程同时访问的数据，那么必须串行化这些访问操作。
为了保证串行化访问，可以使用golang的channel操作或者使用sync和sync/atomic包中的同步原语来保护数据。
2.1 Happens Before    在单个goroutine中，读取和写入的行为必须像它们按照程序指定的顺序执行一样。也就是说，仅当重新排序不会改变语言规范所定义的该goroutine中的行为时，编译器和处理器才可以对单个goroutine中执行的读取和写入进行重新排序。由于此重新排序，一个goroutine观察到的执行顺序可能不同于另一个goroutine所察觉到的执行顺序。例如，如果一个goroutine执行a = 1； b = 2；另一个可能会在b的更新值之前观察b的更新值。
为了指定读取和写入的要求，我们定义happens Before，Go程序中执行内存操作的部分顺序。如果事件e1happens before事件e2，那么我们说e2happens aftere1。同样的，如果e1不happens beforee2并且e1也不happens aftere2，那么我们说e1和e2happens concurrently。
在单个goroutine中，事前发生顺序是程序表示的顺序。
如果同时满足以下两个条件，则允许对变量v的读r观察对v的写w：
 r does not happen before w. There is no other write w&#39; to v that happens after w but before r.  为了保证变量v的读取r观察到对v的特定写入w，请确保w是唯一允许r观察的写入。也就是说，如果同时满足以下两个条件，则保证r遵守w：
 w happens before r.</description>
    </item>
    
    <item>
      <title>Go系列：调度器</title>
      <link>https://cctrip.tech/posts/go_series_scheduler/</link>
      <pubDate>Tue, 07 Apr 2020 17:55:28 +0800</pubDate>
      
      <guid>https://cctrip.tech/posts/go_series_scheduler/</guid>
      <description>系列目录    《Go系列：内存管理》
《Go系列：调度器》
《Go系列：并发》
 1. 介绍    随着技术的不断发展，CPU也在不断发展，出现了多处理器、多核心、CPU缓存、NUMA架构等概念。为了最大化利用CPU的计算能力，软件也在不断发展，出现了并发和并行等概念。而为了支持并发和并行，就需要调度器，用于处理计算任务在不同CPU上的计算。我们主要从系统调度和语言层面的调度来说明。
 2. OS Scheduler    我们的的程序只是一系列机器指令，需要依次执行。为此，操作系统使用了线程的概念，线程的工作就是负责说明并按顺序执行分配给它的指令集。执行将不断进行，直到没有更多指令可以执行。
在操作系统上，我们运行的每个程序都会创建一个进程，并且为每个进程分配一个初始线程。线程具有创建更多线程的能力。所有这些不同的线程彼此独立运行，并且调度决策是在线程级别而不是在进程级别做出的。线程可以同时运行(并发，每个任务运行在同一个的core上)，也可以并行运行(并行，每个任务运行在不同core上同时运行)。线程还维护自己的状态，以允许在本地安全和独立地执行指令。
如果存在可以执行的线程时，OS Scheduler负责确保core不处于空闲状态。它还必须产生一种幻想，即所有可以执行的线程正在同时执行。在创建这种幻想的过程中，Scheduler需要优先运行优先级较高的线程，而不是运行优先级较低的线程。但是，具有较低优先级的线程并无法节省执行时间。Scheduler还需要通过做出快速而明智的决策来最大程度地减少调度延迟。
 2.1 执行指令    程序计数器(PC)有时也称为指令指针(IP)，它使线程可以跟踪要执行的下一条指令。在大多数处理器中，PC指向下一条指令，而不是当前指令。
 2.2 Thread状态     Waiting，这意味着线程已经停止执行并需要等待某些操作才能继续。这可能是由于诸如等待硬件(磁盘，网络)，操作系统(系统调用)或同步调用(原子，互斥体)之类的原因。这些类型的延迟是导致性能下降的根本原因。 Runnable ，这意味着线程需要获得cpu时间，这样它可以执行其分配的机器指令。如果您有很多需要cpu时间的线程，则线程必须等待更长的时间才能获得cpu时间。而且，随着更多线程争夺cpu时间，任何给定线程获得的cpu时间都将缩短。这种类型的调度延迟也可能是性能下降的原因 Executing，这意味着线程已放置在core上并正在执行其机器指令。与应用程序相关的工作已经完成。这是每个人都想要的状态。   2.3 工作类型    CPU-Bound，这项工作永远不会造成线程可能处于等待状态的情况。这是不断进行计算的工作。计算Pi到第N位的线程将是CPU-Bound的。
IO-Bound，这项工作导致线程进入等待状态。这项工作包括请求通过网络访问资源或对操作系统进行系统调用。需要访问数据库的线程将是IO-Bound。我将包括同步事件(互斥量，原子)等导致线程进入等待状态的事件都归为此类。
 2.4 上下文切换    抢占式调度
首先，这意味着在任何给定时间选择要运行的线程时，调度程序都是不可预测的。线程优先级和事件(例如在网络上接收数据)一起使得无法确定调度程序将选择做什么以及何时执行。
其次，这意味着您绝不能基于自己幸运的经历但不能保证每次都发生的某些感知行为来编写代码。让自己思考很容易，因为我已经看到这种情况以1000次相同的方式发生，这是有保证的行为。如果需要在应用程序中确定性，则必须控制线程的同步和编排。
 在内核上交换线程的物理行为称为上下文切换。当调度程序从core中拉出一个excuting线程并将其替换为可runnable线程时，就会发生上下文切换。从运行队列中选择的线程将进入excuting状态。被拉出的线程可以移回runnable状态(如果它仍具有运行能力)或waitting状态(如果由于IO-Bound类型的请求而被替换)。
上下文切换被认为是昂贵的，因为在core上和在core外交换线程都需要时间。上下文切换期间的延迟等待时间量取决于不同的因素，但花费约1000到1500纳秒的时间并非没有道理。虑到硬件应该能够合理地(平均)在每核每纳秒执行12条指令，上下文切换可能会花费大约12000至18k的延迟指令。本质上，您的程序在上下文切换期间将失去执行大量指令的能力。
如果您有一个专注于IO-Bound工作的程序，那么上下文切换将是一个优势。一旦一个线程进入等待状态，另一个处于可运行状态的线程就会代替它。这使核心始终可以工作。这是调度的最重要方面之一。如果有工作要做(线程处于可运行状态)，请不要让core闲置。
如果您的程序专注于CPU-Bound工作，那么上下文切换将成为性能噩梦。由于Thead总是有工作要做，因此上下文切换将阻止该工作的进行。这种情况与IO-Bound工作负载形成鲜明对比。
 2.5 少即是多    制定调度决策时，scheduler还需要考虑和处理更多的事情。您可以控制在应用程序中使用的线程数。当要考虑的线程更多，并且发生IO-Bound工作时，就会出现更多的混乱和不确定性行为。任务需要更长的时间来计划和执行。</description>
    </item>
    
    <item>
      <title>Go系列：内存管理</title>
      <link>https://cctrip.tech/posts/go_series_mem/</link>
      <pubDate>Wed, 01 Apr 2020 17:55:28 +0800</pubDate>
      
      <guid>https://cctrip.tech/posts/go_series_mem/</guid>
      <description>系列目录    《Go系列：内存管理》
《Go系列：并发》
 1.介绍     内存管理是控制和协调软件应用程序访问计算机内存的方式的过程。
 这是软件工程中一个严肃的话题，它使一些人感到困惑，并且对某些人来说是一个黑盒。
2. 内存管理    当软件在计算机上的目标操作系统上运行时，它需要访问计算机RAM（随机存取存储器）以执行以下操作：
 加载自己需要执行的字节码 存储执行的程序使用的数据值和数据结构 加载程序执行所需的所有运行时系统  当软件程序使用内存时，除了用于加载字节码的空间外，还有两个内存区域，即stack内存和heap内存。
2.1 Stack    Stack用于静态内存分配，顾名思义，它是一个后进先出（LIFO）堆栈（将其视为盒子堆栈）。
 由于这种性质，由于不需要查找，因此从堆栈中存储和检索数据的过程非常快，您只需从其最上面的块中存储和检索数据即可。 但这意味着存储在堆栈中的任何数据都必须是有限且静态的（数据大小在编译时是已知的）。 这是函数的执行数据作为堆栈帧存储的位置（因此，这是实际的执行堆栈）。每个帧都是一个空间块，用于存储该功能所需的数据。例如，每当一个函数声明一个新变量时，它就被“压入”到栈顶块中。然后，每次退出函数时，都会清除最顶层的块，从而清除该函数压入堆栈的所有变量。由于此处存储的数据的静态性质，可以在编译时确定这些值。 多线程应用程序每个线程可以有一个堆栈。 堆栈的内存管理非常简单明了，并且由操作系统完成。 存储在堆栈中的典型数据是局部变量（值类型或原语，原语常量），指针和函数框。 这是您会遇到堆栈溢出错误的地方，因为与堆相比，堆栈的大小受到限制。 对于大多数语言，可以存储在堆栈中的值的大小是有限制的。   2.2 Heap    堆用于动态内存分配，与堆栈不同，程序需要使用指针在堆中查找数据（将其视为大型的多级库）。
 它比堆栈慢，因为查找数据的过程涉及更多，但它可以存储比堆栈更多的数据。 这意味着可以在此处存储具有动态大小的数据。 堆在应用程序的线程之间共享。 由于其动态特性，堆管理起来比较棘手，这是大多数内存管理问题的起因，这也是该语言自动内存管理解决方案的起因。 存储在堆中的典型数据是全局变量，引用类型（如对象，字符串，映射和其他复杂数据结构）。 如果您的应用程序尝试使用比分配的堆更多的内存，这就是您遇到内存不足错误的地方（尽管这里还有许多其他因素在起作用，例如GC，压缩）。 通常，对堆中可以存储的值的大小没有限制。当然，为应用程序分配多少内存是有上限的。   2.3 为什么如此重要    与硬盘驱动器不同，RAM不是无限的。 如果程序继续消耗内存而不释放内存，最终它将耗尽内存并崩溃，甚至使操作系统崩溃。 因此，软件程序不仅会继续使用自己喜欢的RAM，还会导致其他程序和进程的内存不足。 因此，大多数编程语言都没有提供让软件开发人员解决此问题的方法，而是提供了执行自动内存管理的方法。 当我们谈论内存管理时，我们主要是在谈论管理堆内存。</description>
    </item>
    
  </channel>
</rss>
